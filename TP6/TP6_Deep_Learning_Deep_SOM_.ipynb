{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zakaria-aabbou/Deep_Learning/blob/main/TP6/TP6_Deep_Learning_Deep_SOM_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5QMbdOl66yK"
      },
      "source": [
        "<h1 style=\"text-align:center;font-size: 3em\"> TP6 : Deep Self-Organizing Map (DeepSOM) </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGVbz0xL66yQ"
      },
      "source": [
        "## Réalisé par : AABBOU ZAKARIA & AMRANI ZOUHIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnpRZ-6h66yR"
      },
      "source": [
        "### Deep Self-Organizing Map (DeepSOM)\n",
        "\n",
        "L'objectif de ce TP est de créer et manipuler un Deep Self-Organizing Map (DeepSOM) afin d'apprendre une nouvelle représentation des données qui met en valeur leurs similarités.\n",
        "\n",
        "\n",
        "###### 1. Importation des librairies "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mN1r_I_d66yS"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import euclidean\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import datasets    \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjQ5z3fZ66yT"
      },
      "source": [
        "###### 2. Classe décrivant l'initialisation et l'apprentissage d'une SOM probabiliste\n",
        "\n",
        "Lisez attentivement ce code et vérifiez que vous ayez bien compris les différentes étapes de l'initialisation et de l'apprentissage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KHUk31SJ66yU"
      },
      "outputs": [],
      "source": [
        "class PrSOM: # Une couche de SOM probabiliste\n",
        "    def __init__(self, data, shape):\n",
        "        self.shape = shape\n",
        "        self.N, self.dim = data.shape\n",
        "        self.data = data\n",
        "     \n",
        "        # Initialisation des prototypes selon les axes de l'ACP\n",
        "        self.pca = PCA().fit(self.data) \n",
        "        var = self.pca.transform(data).std(axis = 0)[0:2]\n",
        "        rangex = np.arange(-var[0],var[0],var[0]*2/self.shape[0])\n",
        "        if len(rangex)>self.shape[0]:\n",
        "            rangex = rangex[:-1]\n",
        "        rangey = np.arange(-var[1],var[1],var[1]*2/self.shape[1])\n",
        "        if len(rangey)>self.shape[1]:\n",
        "            rangey = rangey[:-1]  \n",
        "        self.W = []\n",
        "        for x in rangex:\n",
        "            for y in rangey:\n",
        "                self.W.append([x,y])\n",
        "        self.W = np.hstack((np.array(self.W), np.zeros((len(self.W),self.dim-2))))\n",
        "        self.W =self.pca.inverse_transform(self.W[:,:self.pca.components_.shape[0]])\n",
        "        if np.sum(self.data) == self.N:\n",
        "            self.W[self.W<0]=0\n",
        "        \n",
        "        # Initialization des temperatures (radius de voisinage)\n",
        "        self.s0 = max(1,max(self.shape)/4)\n",
        "        self.sf = 1\n",
        "        self.s = self.s0\n",
        "\n",
        "        # Initialization de beta\n",
        "        d = self.dist(self.W,self.W)\n",
        "        d[d==0] = 'NaN'\n",
        "        self.beta = 1/(np.max(np.nanmin(d,axis=0))**2)\n",
        "\n",
        "        # Nombre de neurones\n",
        "        self.nb_neuron = int(np.product(self.shape))        \n",
        "        \n",
        "        # Coordonnée des neurones\n",
        "        self.coord = []\n",
        "        for i in range(self.shape[0]):\n",
        "            for j in range(self.shape[1]):\n",
        "                self.coord.append([(i,j)])\n",
        "        \n",
        "        # Distance euclidienne entre les prototypes de la première couche\n",
        "        self.distmat = np.zeros((self.nb_neuron, self.nb_neuron))      \n",
        "        for n in range(self.nb_neuron):\n",
        "            for m in range(self.nb_neuron):\n",
        "                self.distmat[n,m] = euclidean(self.coord[n],self.coord[m])\n",
        "\n",
        "        # Initialization de la matrice P de probabilité entre chaque donnée et chaque neurone\n",
        "        self.P = np.zeros((self.N, self.nb_neuron))+1/self.nb_neuron\n",
        "        \n",
        "        # Initialization de la matrice q de probabilité à priori pour chaque neurone\n",
        "        self.q = np.zeros(self.nb_neuron)+1/self.nb_neuron\n",
        "        \n",
        "     \n",
        "    def Kij(self, T): # Calcul de la fonction de voisinage\n",
        "        self.s = self.s0*(self.sf/self.s0)**(T/self.Tmax)\n",
        "        \n",
        "        if self.s>0:\n",
        "            return np.exp(-self.distmat**2/(2*self.s**2))\n",
        "        else:\n",
        "            return np.identity(self.nb_neuron)\n",
        "        \n",
        "        \n",
        "    def train(self,Tmax): #Apprentissage\n",
        "        self.Tmax = Tmax\n",
        "        \n",
        "        for T in range(Tmax):\n",
        "            # Calcul de K, la fonction de voisinage\n",
        "            self.K = self.Kij(T)\n",
        "            \n",
        "            # Affectation des données aux neurones (calcul de P)\n",
        "            self.assign(self.data)\n",
        "            \n",
        "            # Mise à jours de prototypes (calcul de W)\n",
        "            self.update()\n",
        "\n",
        "    \n",
        "    def dist(self, X1, X2):  # Calcul des distances \n",
        "        if np.sum(self.data) == self.N:\n",
        "            return 1/np.sqrt(2)*euclidean_distances(np.sqrt(X1), np.sqrt(X2)) ## Hellinger pour probabilités\n",
        "        else:\n",
        "            return euclidean_distances(X1, X2)  ## Euclidienne pour vecteurs (première couche)\n",
        "            \n",
        "        \n",
        "    def assign(self, X):  ## Calcul de la matrice P de probabilité entre chaque donnée et chaque neurone \n",
        "        # Distance entre les données et les prototypes\n",
        "        self.Dxw = 1/2*self.dist(X, self.W)**2\n",
        "        \n",
        "        # Création de la matrice Q\n",
        "        Q = np.tile(self.q,(self.N,1)).T \n",
        "        \n",
        "        # Calcul de P\n",
        "        self.P = Q * np.dot(self.K,np.exp(-self.beta*self.Dxw.T)) \n",
        "        norm = np.tile(np.sum(self.P, axis=0),(self.nb_neuron,1))+1e-16\n",
        "        self.P = self.P / norm       \n",
        "        \n",
        "        return self.P\n",
        "\n",
        "\n",
        "    def update(self): ## Calcul de W, la matrice des prototypes\n",
        "        # Calcul de P * K\n",
        "        KP = np.dot(self.K,self.P)\n",
        "    \n",
        "        #calcul de W\n",
        "        norm = np.tile(np.sum(KP, axis=1),(self.dim,1)).T\n",
        "        self.W = np.dot(KP,self.data) / norm\n",
        "    \n",
        "    \n",
        "    def Poutput(self): # Calcul et mise en forme de la sortie des couches\n",
        "    \n",
        "        mask = self.shape\n",
        "        P = self.assign(self.data).T\n",
        "        self.out = []\n",
        "\n",
        "        for p in P:\n",
        "            pmat = p.reshape(mask)                            \n",
        "            self.out.append(pmat.reshape((1,mask[0]*mask[1]))[0])\n",
        "            \n",
        "        self.out = np.array(self.out)\n",
        "        \n",
        "        return (self.out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pFgVE7366yX"
      },
      "source": [
        "###### 3. Classe décrivant l'initialisation et l'apprentissage de DeepSOM\n",
        "\n",
        "Créez une classe permettant l'apprentissage de toutes les couches de la DeepSOM à partir d'un ensemble de données d'apprentissage.\n",
        "\n",
        "Faites attention aux points suivants :\n",
        " - Il faut définit les dimentions (shape) de la carte de la première couche.\n",
        " - La taille de la carte diminue de 2 lignes et 2 colonnes pour chaque couche sucessive, avec des dimientions minimale de 4x4.\n",
        " - L'apprentisage prends comme argument un nombre d'itérations.\n",
        " - Les differentes couches sont stockées dans une liste. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BubxvT9266yY"
      },
      "outputs": [],
      "source": [
        "class DeepSOM:\n",
        "    def __init__(self, data, N_layers, shape):\n",
        "        self.data = data\n",
        "        self.N_layers = N_layers\n",
        "        self.shape = shape\n",
        "        self.out = []    # initialisation de la sortie\n",
        "    \n",
        "    \n",
        "    def train(self, Tmax):\n",
        "        X = self.data\n",
        "        self.layers = [] #liste des couches\n",
        "        \n",
        "        # Pour chaque couche :\n",
        "        for i in range(self.N_layers): \n",
        "            \n",
        "            # Mise à jour la taille de la carte \n",
        "            \"\"\" A COMPLETER \"\"\"\n",
        "            self.shape = X.shape\n",
        "            \n",
        "            # Initialisation de la couche\n",
        "            \"\"\" A COMPLETER \"\"\"\n",
        "            self.som = PrSOM(X, self.shape)\n",
        "            \n",
        "            # Apprentissage de la couche\n",
        "            \"\"\" A COMPLETER \"\"\"\n",
        "            self.som.train(Tmax)\n",
        "            \n",
        "            # Calcul de la sortie de la couche\n",
        "            \"\"\" A COMPLETER \"\"\"\n",
        "            self.out_layer = self.som.Poutput()\n",
        "            \n",
        "            # Mise en mémoire de la couche\n",
        "            \"\"\" A COMPLETER \"\"\"\n",
        "            self.layers.append(self.out_layer)\n",
        "        \n",
        "        self.out = X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVkYdHdE66yZ"
      },
      "source": [
        "###### 4. Application de la DeepSOM sur des jeux de données \n",
        "\n",
        " 1. Chargez des données en utilisant 'dataset' de la librairie sklearn (par exemple les données 'iris'). \n",
        " 2. Lancez l'apprentissage de DeepSOM sur ces données.\n",
        " 3. Affichez le score de chaque couche, défini comme la moyenne du rapport entre la plus petite et la plus grande distance de chaque donnée avec les autres données ( => mean(dist_min/dist_max)). Vérifiez que le score décroît de la première couche à la dernière.\n",
        " 4. Visualisez la sortie du réseau avec 'imshow', avec triant les données selon leurs classes; afin de vérifier que les données d'une même classe ont une représentation identique. Utilisez une \n",
        " \n",
        "Testez l'algorithme sur différents jeux de données, en faisant varier les paramètres (nombre de couches, dimensions de la carte de la première couche) afin d'obtenir les meilleurs résultats.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wnlWjSaq66yZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IyiFQoCe66ya"
      },
      "outputs": [],
      "source": [
        "# Chargement des données\n",
        "\"\"\" A COMPLETER \"\"\"\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "# normalisation des données\n",
        "normalized_X = preprocessing.normalize(X)\n",
        "\n",
        "# Séparation des données en test et entrainement\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKdtgNsL66yb",
        "outputId": "683608d2-99c4-4608-b121-0b7968bcfd75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jonXE_IV66yc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Création de la DeepSOM\n",
        "\"\"\" A COMPLETER \"\"\"\n",
        "data = X_train\n",
        "nb_layers = 10\n",
        "#shape = (a,b)\n",
        "shape = X_train.shape\n",
        "S = DeepSOM(data, nb_layers, shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zg8ohBld66yc"
      },
      "outputs": [],
      "source": [
        "# Apprentissage de la DeepSOM\n",
        "\"\"\" A COMPLETER \"\"\"\n",
        "Tmax = 100\n",
        "S.train(Tmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMDAmHY566yd"
      },
      "outputs": [],
      "source": [
        "# Affichage des scores Ijs pour chaque couche\n",
        "l=0\n",
        "i=0\n",
        "for lay in S.layers:\n",
        "    l+=1\n",
        "    #i\n",
        "    \"\"\" A COMPLETER \"\"\"\n",
        "    mi = S.som.dist(data[i], data)\n",
        "    ma = S.som.dist(data[i], data)\n",
        "    index = np.mean(mi/ma)\n",
        "    print(\"Couche \",l,\": score = \", round(index,3))\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "1waranZo66yd",
        "outputId": "49af7902-8c91-41e4-e132-e6bbf0b91f2e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c6defa786ab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpcolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: dist() missing 2 required positional arguments: 'X1' and 'X2'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualisation des représentations des données en sortie du réseau\n",
        "\"\"\" A COMPLETER \"\"\"\n",
        "from pylab import plot,axis,show,pcolor,colorbar,bone\n",
        "bone()\n",
        "pcolor(S.som.dist().T)\n",
        "colorbar()\n",
        "markers = ['o', 's']\n",
        "colors = ['r', 'g']\n",
        "for i, x in enumerate(X):\n",
        "    w = S.som.winner(x)\n",
        "    plot(w[0] + 0.5,\n",
        "         w[1] + 0.5,\n",
        "         markers[y[i]],\n",
        "         markeredgecolor=colors[y[i]],\n",
        "         markerfacecolor='None',\n",
        "         markersize=10,\n",
        "         markeredgewidth=2)\n",
        "show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDvvpuZO66ye"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUA-tGxo66ye"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2dUFg9A66ye"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "q2p8pSSS66ye",
        "outputId": "cb71099c-e252-4018-f298-1776520e83f2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1b4d55c7e15b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"\"\" A COMPLETER \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Couche \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\": score = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mi' is not defined"
          ]
        }
      ],
      "source": [
        "# Affichage des scores Ijs pour chaque couche\n",
        "l=0\n",
        "for lay in S.layers:\n",
        "    l+=1\n",
        "    \n",
        "    \"\"\" A COMPLETER \"\"\"\n",
        "\n",
        "    index = np.mean(mi/ma)\n",
        "    print(\"Couche \",l,\": score = \", round(index,3))\n",
        "\n",
        "# Visualisation des représentations des données en sortie du réseau\n",
        "\"\"\" A COMPLETER \"\"\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TP6 Deep Learning - Deep SOM .ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}